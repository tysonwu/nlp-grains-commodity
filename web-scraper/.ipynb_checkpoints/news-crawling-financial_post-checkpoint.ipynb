{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling Financial Post\n",
    "\n",
    "- The program mainly makes use of `requests` and `bs4` packages.\n",
    "\n",
    "- The program loops through the search result pages and stores relevant text data.\n",
    "\n",
    "- The program loops through the pre-defined keywords and pre-defined number of results.\n",
    "\n",
    "- Example URL format: https://financialpost.com/search/?search_text=wheat&date_range=-7300d&sort=desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [14:37<00:00,  2.95s/it]\n",
      "100%|██████████| 448/448 [22:42<00:00,  3.04s/it]\n",
      "100%|██████████| 405/405 [20:12<00:00,  2.99s/it]\n",
      "100%|██████████| 87/87 [04:09<00:00,  2.87s/it]\n",
      "100%|██████████| 148/148 [07:06<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"\n",
    "pre-determined KEYWORDS dict = {<query>: <total no. of results>}\n",
    "\"\"\"\n",
    "KEYWORDS = {'soybean': 2963, 'wheat': 4476, 'corn': 4041, 'oats': 863, 'rice': 1480}\n",
    "OUTPUT_PATH = './financial_post/'\n",
    "\n",
    "\n",
    "def get_raw_html(query, count):\n",
    "    url = f'https://financialpost.com/search/?search_text={query}&date_range=-7300d&sort=desc&from={count}'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36',\n",
    "        'Content-Type': 'text/html',\n",
    "    }\n",
    "    contents = requests.get(url,headers=headers).text\n",
    "    time.sleep(0.5)\n",
    "#     print(f'Scraped one page: {query} - {page}')\n",
    "    return contents\n",
    "\n",
    "\n",
    "def html_transform(raw_html, query):\n",
    "    \"\"\"\n",
    "    arg raw_html: raw html string\n",
    "    return: a list of dict\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(raw_html,'lxml')\n",
    "    raw_articles = soup.find_all('article')\n",
    "    url = [r.find('a', class_='article-card__link').get('href') for r in raw_articles]\n",
    "    headline = [r.find('h3').text for r in raw_articles]\n",
    "    # body = [[s.text for s in r.find('div', class_='field-body').find_all('p')] for r in raw_articles]\n",
    "    footer = [r.find('span', class_='article-card__time').text for r in raw_articles]\n",
    "    cat = [r.find('span', class_='article-card__category').text for r in raw_articles]\n",
    "    result = [{'headline':h, 'metadata':f, 'url': u, 'cat': c, 'query':query} for h,f,u,c in zip(headline,footer,url,cat)]\n",
    "    return result\n",
    "\n",
    "\n",
    "for query, n in KEYWORDS.items():\n",
    "    for page in tqdm(range(0,math.ceil(n/10)*10,10)):\n",
    "        raw_htmls = get_raw_html(query,page) # returns a string of raw html\n",
    "        result = html_transform(raw_htmls, query)\n",
    "\n",
    "        # writing to json file\n",
    "        if not os.path.isfile(f'{OUTPUT_PATH}{query}.json'): # if file is empty\n",
    "            with open(f'{OUTPUT_PATH}{query}.json','w+') as f:\n",
    "                json.dump({'data': result}, f)\n",
    "        else:\n",
    "            with open(f'{OUTPUT_PATH}{query}.json','r') as f:\n",
    "                data = json.load(f)\n",
    "            data['data'] += result\n",
    "            with open(f'{OUTPUT_PATH}{query}.json','w') as f:\n",
    "                json.dump(data,f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
